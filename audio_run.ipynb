{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stc/rybin-as/miniconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import models \n",
    "import datasets\n",
    "import torch\n",
    "import torchaudio\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1692/1692 [01:17<00:00, 21.96it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/mnt/storage/posokhov/emo_cls/data'\n",
    "train = pd.read_csv('/mnt/storage/posokhov/emo_cls/filterd_train.csv')\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "le.fit(train['EmotionMaxVote'].values)\n",
    "\n",
    "\n",
    "win_length = 1000\n",
    "hop_length = 500\n",
    "n_mels = 128\n",
    "mel = torchaudio.transforms.MelSpectrogram(hop_length=hop_length, \n",
    "                                                 n_mels=n_mels, \n",
    "                                                 win_length=win_length, \n",
    "                                                 n_fft=win_length)\n",
    "# mfcc = torchaudio.transforms.MFCC(n_mfcc=40, \n",
    "#                                             log_mels=True,\n",
    "#                                             melkwargs={'hop_length':hop_length, \n",
    "#                                             'n_mels':n_mels, \n",
    "#                                             'win_length':win_length, \n",
    "#                                             'n_fft':win_length})\n",
    "aggregator = lambda x: torch.mean(x, axis=-1)\n",
    "\n",
    "data = datasets.audio_dataset(data_dir=data_dir, fnames=train['video'], \n",
    "                   labels=train['EmotionMaxVote'], pad_size='mean', le=le, \n",
    "                   extractor=mel, aggregator=None, as_numpy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282527"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = torch.utils.data.random_split(data, [1000, 692])\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=True)\n",
    "data.pad_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: audio/mfcc\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type             | Params\n",
      "------------------------------------------------\n",
      "0  | conv1     | Conv2d           | 12.8 K\n",
      "1  | bn1       | BatchNorm2d      | 64    \n",
      "2  | pool1     | MaxPool2d        | 0     \n",
      "3  | drop1     | Dropout          | 0     \n",
      "4  | conv2     | Conv2d           | 3.1 K \n",
      "5  | bn2       | BatchNorm2d      | 64    \n",
      "6  | pool2     | MaxPool2d        | 0     \n",
      "7  | drop2     | Dropout          | 0     \n",
      "8  | conv3     | Conv2d           | 6.2 K \n",
      "9  | bn3       | BatchNorm2d      | 128   \n",
      "10 | pool3     | MaxPool2d        | 0     \n",
      "11 | drop3     | Dropout          | 0     \n",
      "12 | drop4     | Dropout          | 0     \n",
      "13 | fc4       | Linear           | 3.6 K \n",
      "14 | f1_train  | F1Score          | 0     \n",
      "15 | f1_val    | F1Score          | 0     \n",
      "16 | acc_train | Accuracy         | 0     \n",
      "17 | acc_val   | Accuracy         | 0     \n",
      "18 | loss      | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "26.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.0 K    Total params\n",
      "0.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stc/rybin-as/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/stc/rybin-as/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/posokhov/emo_cls/models.py:184: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.nn.functional.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]f1 tensor(0.1406, device='cuda:0') acc tensor(0.1406, device='cuda:0')\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stc/rybin-as/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 54/54 [00:40<00:00,  1.33it/s, loss=1.76, v_num=0]f1 tensor(0.3942, device='cuda:0') acc tensor(0.3942, device='cuda:0')\n",
      "Epoch 0: 100%|██████████| 54/54 [00:40<00:00,  1.33it/s, loss=1.76, v_num=0]f1 tensor(0.3560, device='cuda:0') acc tensor(0.3560, device='cuda:0')\n",
      "Epoch 1: 100%|██████████| 54/54 [01:19<00:00,  1.47s/it, loss=1.55, v_num=0]f1 tensor(0.4116, device='cuda:0') acc tensor(0.4116, device='cuda:0')\n",
      "Epoch 1: 100%|██████████| 54/54 [01:19<00:00,  1.47s/it, loss=1.55, v_num=0]f1 tensor(0.3955, device='cuda:0') acc tensor(0.3955, device='cuda:0')\n",
      "Epoch 2:  22%|██▏       | 12/54 [01:26<05:04,  7.25s/it, loss=1.5, v_num=0]  "
     ]
    }
   ],
   "source": [
    "model = models.pl_cnn2d(y_kernel=5, n_mels=n_mel, n_input=2, stride=(128, 1), n_output=len(le.classes_))\n",
    "logger = pl.loggers.tensorboard.TensorBoardLogger(\"audio\", name=\"mfcc\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=20, logger=logger, log_every_n_steps=1)\n",
    "trainer.fit(model, trainloader, testloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d42659e231ee60b4434f7142872fe61f6941c0ce0d4f9724cf7f98100868462"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
